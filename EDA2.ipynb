{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "def add_dummies(df: pd.DataFrame, Y: pd.Series):\n",
    "    \n",
    "    mlb = MultiLabelBinarizer()\n",
    "    # Keywords: (10003 unique)\n",
    "    dummy_keywords =pd.DataFrame(mlb.fit_transform(df['Keywords.id'].apply(lambda x: x if x else tuple())),\n",
    "                                    columns=[f\"keyword_{kw_id}\" for kw_id in mlb.classes_], \n",
    "                                    index=df.index)\n",
    "\n",
    "    dummy_keywords = dummy_keywords.loc[:, dummy_keywords.sum() > 1] # Removes keyword with 1 appearence\n",
    "\n",
    "    tree_model = ExtraTreesClassifier(n_estimators=50)\n",
    "    tree_model = tree_model.fit(dummy_keywords, Y)\n",
    "    \n",
    "    model = SelectFromModel(tree_model, prefit=True)\n",
    "    X_new = model.transform(dummy_keywords)\n",
    "    important_keywords = dummy_keywords.loc[:, model.get_support()] # Returns only selected features only\n",
    "    df = pd.concat([df, important_keywords], axis=1)\n",
    "\n",
    "    dummy_genres = pd.DataFrame(mlb.fit_transform(df.genres),\n",
    "                            columns=[f\"genre_{cl}\" for cl in mlb.classes_], \n",
    "                            index=df.index)\n",
    "    df = pd.concat([df, dummy_genres], axis=1)\n",
    "\n",
    "    dummy_companies = pd.DataFrame(mlb.fit_transform(df['production_companies.id'].apply(lambda x: x if x else tuple())),\n",
    "                                columns=[f\"company_{cl}\" for cl in mlb.classes_], \n",
    "                                index=df.index)\n",
    "    dummy_companies = dummy_companies.loc[:, dummy_companies.sum() > 1] # Removes companies with 1 appearence     \n",
    "    df = pd.concat([df, dummy_companies], axis=1) # Maybe biggest company size is enough...   \n",
    "\n",
    "    dummy_countries =pd.DataFrame(mlb.fit_transform(df.production_countries),\n",
    "                                columns=[f\"country_{cl}\" for cl in mlb.classes_], \n",
    "                                index=df.index)\n",
    "    df = pd.concat([df, dummy_countries], axis=1)\n",
    "\n",
    "    dummy_lang = pd.DataFrame(mlb.fit_transform(df.spoken_languages),\n",
    "                            columns=[f\"spoken_lang_{cl}\" for cl in mlb.classes_], \n",
    "                            index=df.index)\n",
    "    df = pd.concat([df, dummy_lang], axis=1)\n",
    "\n",
    "    dummy_cast = pd.DataFrame(mlb.fit_transform(df['cast.id'].apply(lambda x: x if x else tuple())),\n",
    "                                columns=[f\"cast_{cl}\" for cl in mlb.classes_], \n",
    "                                index=df.index)\n",
    "    dummy_cast = dummy_cast.loc[:, dummy_cast.sum() > 20] # Removes cast with lower movies than 20  \n",
    "    df = pd.concat([df, dummy_cast], axis=1)\n",
    "\n",
    "    # Original Language dummy:\n",
    "    dummy_orig_lang = pd.get_dummies(df.original_language, prefix=\"original_lang_\")\n",
    "    dummy_orig_lang = dummy_orig_lang.loc[:, dummy_orig_lang.sum() > 1]\n",
    "\n",
    "    df = pd.concat([df, dummy_orig_lang], axis=1)     \n",
    "\n",
    "\n",
    "def map_and_max(collection, mapping_dict):\n",
    "    return max(map(mapping_dict.get, collection)) if collection else None\n",
    "\n",
    "def eval_or_nan(obj):\n",
    "    if obj and pd.notnull(obj) and isinstance(obj, str):\n",
    "        return eval(obj)\n",
    "    return None\n",
    "\n",
    "def map_attribute(obj, attribute_name: str):\n",
    "    if obj:\n",
    "        iterable = eval(obj) if isinstance(obj, str) else obj\n",
    "        return tuple(map(lambda x: x.get(attribute_name, None), iterable))\n",
    "    return None\n",
    "\n",
    "def features_flattening(df: pd.DataFrame):\n",
    "    df['belongs_to_collection'] = df.belongs_to_collection.apply(eval_or_nan)\n",
    "    df['belongs_to_collection.id'] = df.belongs_to_collection\\\n",
    "                                            .apply(lambda x: None if pd.isna(x) else x['id']).astype('Int64')\n",
    "\n",
    "\n",
    "    df['genres'] = df.genres.apply(lambda gs: tuple(g['name'] for g in eval(gs)))\n",
    "\n",
    "    df['production_companies'] = df.production_companies.apply(eval_or_nan)\n",
    "    df['production_companies.id'] = df.production_companies\\\n",
    "                                            .apply(lambda companies: map_attribute(companies, 'id'))\n",
    "    df['production_companies.origin_country'] = df.production_companies\\\n",
    "                                            .apply(lambda companies: map_attribute(companies, 'origin_country'))\n",
    "\n",
    "    df['production_countries'] = df.production_countries.apply(lambda countries: map_attribute(countries, 'iso_3166_1'))\n",
    "\n",
    "    df['release_date'] = pd.to_datetime(df.release_date)\n",
    "    df['release_month'] = df.release_date.dt.month\n",
    "    df['release_year'] = df.release_date.dt.year\n",
    "\n",
    "    df['spoken_languages'] = df.spoken_languages.apply(lambda langs: map_attribute(langs, 'iso_639_1'))\n",
    "\n",
    "    df['Keywords'] = df.Keywords.apply(eval_or_nan)\n",
    "    df['Keywords.id'] =df.Keywords.apply(lambda keywords: map_attribute(keywords, 'id')) # TODO: Maybe keep words?\n",
    "\n",
    "    df['cast'] = df.cast.apply(eval_or_nan)\n",
    "    df['cast.id'] = df.cast.apply(lambda actors: map_attribute(actors, 'id'))\n",
    "    df['cast.gender'] = df.cast.apply(lambda actors: map_attribute(actors, 'gender')) # Gender ratio\n",
    "\n",
    "    df['crew'] = df.crew.apply(eval)\n",
    "    df['crew.id'] = df.crew.apply(lambda crew: map_attribute(crew, 'id'))\n",
    "    df['crew.gender'] = df.crew.apply(lambda crew: map_attribute(crew, 'gender')) # Gender ratio\n",
    "    df['crew.department'] = df.crew.apply(lambda crew: map_attribute(crew, 'department')) # Dept size\n",
    "    \n",
    "    df.drop(['crew', 'cast', 'Keywords', 'belongs_to_collection', 'release_date'], axis=1, inplace=True)\n",
    "\n",
    "def missing_value_imputation(df: pd.DataFrame):\n",
    "    df.runtime.fillna(0, inplace=True)\n",
    "\n",
    "def get_element_frequency(df, attribute):\n",
    "    return Counter(df[attribute].dropna().sum())\n",
    "\n",
    "# Gender actor ratio: 0 is unspecified, 1 is female, and 2 is male\n",
    "def genders_ratio(genders):\n",
    "    arr = np.array(genders)\n",
    "    males = (arr == 1).sum()\n",
    "    females = (arr == 2).sum()\n",
    "    if males or females:\n",
    "        return males / (females+males)\n",
    "    return 0\n",
    "\n",
    "def feature_extraction(df: pd.DataFrame):\n",
    "    removed_columns = ['backdrop_path', 'homepage', 'poster_path', 'imdb_id', 'video']\n",
    "    X = df[[col for col in df.columns if col not in removed_columns]].copy().set_index('id')\n",
    "\n",
    "    Y = X['revenue'].copy()\n",
    "    X.drop('revenue', axis=1, inplace=True)\n",
    "\n",
    "    features_flattening(X)\n",
    "    missing_value_imputation(X)\n",
    "    \n",
    "    X['collection_size'] = X.groupby('belongs_to_collection.id')['belongs_to_collection.id']\\\n",
    "                                    .transform('count').fillna(0).astype(int).copy()\n",
    "\n",
    "    company_size_dict = get_element_frequency(X, 'production_companies.id') # {company_id : company_size}\n",
    "\n",
    "    X['biggest_company_size'] = X['production_companies.id']\\\n",
    "                                        .apply(lambda companies: map_and_max(companies, company_size_dict))\\\n",
    "                                        .fillna(0).astype(int)\n",
    "\n",
    "    id_country_set = set(X.production_companies\n",
    "                        .apply(lambda xs: [(x['id'], x['origin_country']) for x in xs if x['origin_country']])\n",
    "                        .sum()\n",
    "                    )\n",
    "                    \n",
    "    company_per_country = Counter(country for comp_id, country in id_country_set)\n",
    "\n",
    "    company_per_country[''] = 0 # Update no-countries to 0\n",
    "\n",
    "    X['biggest_country'] = X['production_companies.origin_country']\\\n",
    "                                    .apply(lambda companies: map_and_max(companies, company_per_country))\\\n",
    "                                    .fillna(0).astype(int)\n",
    "\n",
    "    country_size_dict = get_element_frequency(X, 'production_countries') # {country : movie_count}\n",
    "\n",
    "    X['biggest_country_size'] = X['production_countries']\\\n",
    "                                        .apply(lambda countries: map_and_max(countries, country_size_dict))\\\n",
    "                                        .fillna(0).astype(int)\n",
    "\n",
    "\n",
    "    X['cast.gender_ratio'] = X['cast.gender'].apply(genders_ratio)\n",
    "\n",
    "    X['spoken_lang_num'] = X.spoken_languages.apply(len)\n",
    "\n",
    "    X['overview_word_count'] = X.overview.apply(lambda x: len(x.split(\" \")) if pd.notnull(x) else 0) # Overview word-count\n",
    "    X['tagline_char_count'] = X.tagline.apply(lambda x: len(x) if pd.notnull(x) else 0) # tagline character-count\n",
    "    X['title_char_count'] = X.title.apply(lambda x: len(x) if pd.notnull(x) else 0) # title character-count\n",
    "                                        \n",
    "    # Dept. size:\n",
    "\n",
    "    dept_size_df = X['crew.department'].apply(lambda x: pd.Series(Counter(x)))\\\n",
    "                        .add_suffix('_depart_size')\\\n",
    "                        .astype('Int64')\n",
    "    dept_size_df.dropna(axis=1, thresh= dept_size_df.shape[0] * 0.20, inplace=True) # Drop columns with less than 20% data\n",
    "    dept_size_df.fillna(0, inplace=True) # Missing value imputation with 0\n",
    "    X = pd.concat([X, dept_size_df], axis=1)\n",
    "\n",
    "    add_dummies(X, Y)\n",
    "\n",
    "    tuple_fields = ['genres', 'spoken_languages', 'production_countries', 'production_companies.id', 'Keywords.id', 'cast.id', 'cast.gender', 'crew.id', 'crew.gender', 'crew.department', 'belongs_to_collection.id', 'production_companies', 'production_companies.origin_country']\n",
    "    text_fields = ['original_language', 'original_title', 'overview', 'status', 'tagline', 'title']\n",
    "\n",
    "    X.drop(tuple_fields+text_fields, axis=1, inplace=True)\n",
    "\n",
    "    return X, Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv('data/train.tsv',delimiter='\\t')\n",
    "test_raw = pd.read_csv('data/test.tsv',delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y = feature_extraction(train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X, test_Y = feature_extraction(test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2.4260436358907187"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier().fit(train_X, train_Y)\n",
    "pred = clf.predict(test_X)\n",
    "\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "np.sqrt(mean_squared_log_error(test_Y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37564bitbasecondad107695b9a69403d88bbb2cd5dc32396",
   "display_name": "Python 3.7.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}